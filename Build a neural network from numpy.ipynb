{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traget: using pyton and mumpy implement a neural network framework\n",
    "Node:\n",
    "+ forwrd: *function*, how to calculate the inputs\n",
    "+ backwards: *function*, how to get the gradients when backpropogation\n",
    "+ gradients: *Mapper*, the gradient map this node of its inputs node\n",
    "+ inputs: *List*\n",
    "+ outputs: *list*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 面向对象的方式来组织\n",
    "\n",
    "## 构建基类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    each node in neural network will have these arrtributes and methods\n",
    "    \"\"\"\n",
    "    def __init__(self,inputs=[]):\n",
    "        \"\"\"\n",
    "        if the node is the operator of 'ax+b', the inputs will be x node, and the outputs of this is its successors.\n",
    "        and the value is 'ax + b'\n",
    "        \"\"\"\n",
    "        self.inputs = inputs # input list <- C, Java <- 匈牙利命名法 -> Python 特别不建议 ， python定义时无类型\n",
    "        #self.outputs = outputs # output list \n",
    "        self.value = None\n",
    "        self.outputs = []\n",
    "        self.gradients = {}\n",
    "        \n",
    "        for node in self.inputs: # variable without type , plural \n",
    "            node.outputs.append(self)\n",
    "    \n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        forward propogation\n",
    "        compute the output value based on input nodes and store the value into \"self.value\"\n",
    "        \"\"\"\n",
    "        raise NotImplemented  # imaginary class\n",
    "    \n",
    "    def backward(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Back propogation\n",
    "        compute the gradient of each input node and store the value into \"self.gradients\"\n",
    "        \"\"\"\n",
    "        return NotImplemented  # imaginary class\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建子类\n",
    "+ Input node\n",
    "+ Linear Node\n",
    "+ Sigmoid Node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Node):\n",
    "    def __init__(self, name=''):\n",
    "        Node.__init__(self, inputs=[])\n",
    "        self.name= name\n",
    "    \n",
    "    def forward(self, value=None):\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {}\n",
    "        \n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Input Node: {}'.format(self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[1,2],[2,4],[3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 25])"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        self.w_node = weights\n",
    "        self.x_node = nodes\n",
    "        self.b_node = bias\n",
    "        Node.__init__(self,inputs = [nodes, weights, bias])\n",
    "        \n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        compute the wx+b using numpy\n",
    "        \"\"\"\n",
    "        self.value = np.dot(self.x_node.value, self.w_node.value)+self.b_node.value\n",
    "        \n",
    "    def backward(self):\n",
    "        for node in self.outputs:\n",
    "            grad_cost = node.gradients[self]\n",
    "            \n",
    "            self.gradients[self.w_node]= np.dot(self.x_node.value.T,grad_cost) # partial(loss)/partial(w) = partial(loss)/partial(self)*x\n",
    "            self.gradients[self.b_node]= np.sum(grad_cost * 1, axis = 0, keepdims = False) # partial(loss)/partial(b) = partial(loss)/partial(self)*1\n",
    "            self.gradients[self.x_node]= np.dot(grad_cost, self.w_node.value.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Linear(Node):\n",
    "#     def __init__(self, nodes, weights, bias):\n",
    "#         self.w_node = weights\n",
    "#         self.x_node = nodes\n",
    "#         self.b_node = bias\n",
    "#         Node.__init__(self, inputs=[nodes, weights, bias])\n",
    "    \n",
    "#     def forward(self): \n",
    "#         \"\"\"compute the wx + b using numpy\"\"\"\n",
    "#         self.value = np.dot(self.x_node.value, self.w_node.value) + self.b_node.value\n",
    "        \n",
    "    \n",
    "#     def backward(self):\n",
    "        \n",
    "#         for node in self.outputs:\n",
    "#             #gradient_of_loss_of_this_output_node = node.gradient[self]\n",
    "#             grad_cost = node.gradients[self]\n",
    "            \n",
    "#             self.gradients[self.w_node] = np.dot(self.x_node.value.T, grad_cost)\n",
    "#             self.gradients[self.b_node] = np.sum(grad_cost * 1, axis=0, keepdims=False)\n",
    "#             self.gradients[self.x_node] = np.dot(grad_cost, self.w_node.value.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    def __init__(self,node):\n",
    "        Node.__init__(self,[node])\n",
    "        self.x_node = node\n",
    "        \n",
    "    def _sigmoid(self,x):\n",
    "        return 1./(1+np.exp(-1 * x ))\n",
    "    \n",
    "    def forward(self):\n",
    "        self.value  = self._sigmoid(self.x_node.value) \n",
    "        \n",
    "    def backward(self):\n",
    "        y = self.value\n",
    "        \n",
    "        self.partial = y * (1-y)\n",
    "        \n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            \n",
    "            self.gradients[self.x_node] = grad_cost * self.partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.array([[1,1],[1,2],[1,3]])\n",
    "W2 = np.array([[0,1],[3,2],[2,3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 2],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3]])"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 1, 3])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.reshape(-1,1).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(W1.reshape(-1,1)-W2.reshape(-1,1))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    def __init__(self,y_true, y_hat):\n",
    "        self.y_true_node = y_true\n",
    "        self.y_hat_node = y_hat\n",
    "        Node.__init__(self, inputs = [y_true, y_hat])\n",
    "         \n",
    "    def forward(self):\n",
    "        y_true_flatten = self.y_true_node.value.reshape(-1,1)\n",
    "        y_hat_flatten = self.y_hat_node.value.reshape(-1,1)\n",
    "        self.diff = y_true_flatten-y_hat_flatten\n",
    "        self.value = np.mean(self.diff ** 2)\n",
    "        \n",
    "    def backward(self):\n",
    "        n = self.y_hat_node.value.shape[0] # shape [0] 第一个维度大小；        \n",
    "        self.gradients[self.y_true_node] =  (2 / n) * self.diff\n",
    "        self.gradients[self.y_hat_node] = (-2 / n) * self.diff\n",
    "        \n",
    "    def __str__(self):\n",
    "        print('MSE with ****')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_one_batch(topological_sorted_graph):\n",
    "    # graph 经过拓扑排序之后的一个list\n",
    "    for node in topological_sorted_graph:\n",
    "        node.forward()\n",
    "        \n",
    "    for node in topological_sorted_graph[::-1]:\n",
    "        node.backward()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(data_with_value):\n",
    "    feed_dict = data_with_value\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "    \n",
    "    G = {}\n",
    "    nodes = [ n for n in input_nodes]\n",
    "    while len(nodes)>0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out' : set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = { 'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "    L = []\n",
    "    S  = set(input_nodes)\n",
    "    while len(S)>0:\n",
    "        n = S.pop()\n",
    "        \n",
    "        if isinstance(n,Input):\n",
    "            n.value = feed_dict[n]\n",
    "            ## if n is Input node, set a value as feed_dic[n]\n",
    "            ## else, n's value is calculated as its inbounds\n",
    "            \n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edge add to S\n",
    "            if len(G[m]['in'])== 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_update(trainable_nodes, learning_rate = 1e-2):\n",
    "    for t in trainable_nodes:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]  # partial(loss)/partial(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = (X_-np.mean(X_, axis=0))/np.std(X_,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_, b1_= np.random.randn(n_features, n_hidden), np.zeros(n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2_, b2_= np.random.randn(n_hidden, 1), np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W3_,b3_ = np.random.randn(n_hidden2,1), np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a graph conneciton\n",
    "### Build nodes in this graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Input(name = 'X'), Input(name = 'y')  # Tensorflor -> placeholder\n",
    "W1, b1 = Input(name = 'W1'), Input(name = 'b1')\n",
    "W2, b2 = Input(name = 'W2'), Input(name = 'b2')\n",
    "#W3, b3 = Input(name = 'W3'), Input(name = 'b3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd build connection relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_output = Linear(X, W1, b1)\n",
    "sigmoid_output = Sigmoid(linear_output)\n",
    "#linear_output_2 = Linear(sigmoid_output)\n",
    "yhat = Linear(sigmoid_output, W2, b2)\n",
    "loss = MSE(y, yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node_with_value = {  # feed_dict in Tensorflow\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    W2: W2_,\n",
    "    b1: b1_,\n",
    "    b2: b2_\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = topological_sort(input_node_with_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Input Node: b1,\n",
       " Input Node: b2,\n",
       " Input Node: W1,\n",
       " Input Node: X,\n",
       " Input Node: W2,\n",
       " Input Node: y,\n",
       " <__main__.Linear at 0x178653404e0>,\n",
       " <__main__.Sigmoid at 0x17865340518>,\n",
       " <__main__.Linear at 0x178653406a0>,\n",
       " <__main__.MSE at 0x178653406d8>]"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 6, 8, 8, 4, 2, 6, 3, 0])"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(10), size = 10, replace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(range(X_.shape[0]), size = 10, replace = True)\n",
    "X_batch = X_[indices]\n",
    "y_batch = y_[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.4, 16.3, 23.4, 20.6,  8.4, 17.1, 30.8, 15.6,  5.6, 15.2])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 48, 413,  73,  94, 438, 331,  39, 146, 400,  22])"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(dictionary):\n",
    "    return topological_sort(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch : 1, loss = 336.948\n",
      " Epoch : 101, loss = 10.882\n",
      " Epoch : 201, loss = 8.039\n",
      " Epoch : 301, loss = 6.556\n",
      " Epoch : 401, loss = 4.856\n",
      " Epoch : 501, loss = 6.808\n",
      " Epoch : 601, loss = 5.391\n",
      " Epoch : 701, loss = 4.255\n",
      " Epoch : 801, loss = 5.716\n",
      " Epoch : 901, loss = 4.762\n",
      " Epoch : 1001, loss = 4.517\n",
      " Epoch : 1101, loss = 4.624\n",
      " Epoch : 1201, loss = 4.844\n",
      " Epoch : 1301, loss = 3.710\n",
      " Epoch : 1401, loss = 4.245\n",
      " Epoch : 1501, loss = 4.248\n",
      " Epoch : 1601, loss = 3.778\n",
      " Epoch : 1701, loss = 4.784\n",
      " Epoch : 1801, loss = 4.793\n",
      " Epoch : 1901, loss = 4.609\n",
      " Epoch : 2001, loss = 4.855\n",
      " Epoch : 2101, loss = 3.906\n",
      " Epoch : 2201, loss = 4.591\n",
      " Epoch : 2301, loss = 3.677\n",
      " Epoch : 2401, loss = 4.183\n",
      " Epoch : 2501, loss = 4.250\n",
      " Epoch : 2601, loss = 3.626\n",
      " Epoch : 2701, loss = 3.630\n",
      " Epoch : 2801, loss = 3.893\n",
      " Epoch : 2901, loss = 3.455\n",
      " Epoch : 3001, loss = 3.326\n",
      " Epoch : 3101, loss = 3.541\n",
      " Epoch : 3201, loss = 4.038\n",
      " Epoch : 3301, loss = 3.731\n",
      " Epoch : 3401, loss = 4.007\n",
      " Epoch : 3501, loss = 4.041\n",
      " Epoch : 3601, loss = 3.660\n",
      " Epoch : 3701, loss = 3.625\n",
      " Epoch : 3801, loss = 3.466\n",
      " Epoch : 3901, loss = 3.200\n",
      " Epoch : 4001, loss = 3.708\n",
      " Epoch : 4101, loss = 3.282\n",
      " Epoch : 4201, loss = 3.258\n",
      " Epoch : 4301, loss = 4.140\n",
      " Epoch : 4401, loss = 3.214\n",
      " Epoch : 4501, loss = 3.927\n",
      " Epoch : 4601, loss = 3.420\n",
      " Epoch : 4701, loss = 3.747\n",
      " Epoch : 4801, loss = 3.465\n",
      " Epoch : 4901, loss = 3.572\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "epochs = 5000\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "steps_per_epoch = X_.shape[0] // batch_size\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    \n",
    "    for batch in range(steps_per_epoch):\n",
    "        #indices = np.random.choice(range(X_.shape[0]), size = 10, replace = True)\n",
    "        #X_batch = X_[indices]\n",
    "        #y_batch = y_[indices]\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples = batch_size)  #  The same meaning with the above code\n",
    "        \n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "        \n",
    "#         input_node_with_value = { \n",
    "#             X: X_batch,\n",
    "#             y: y_batch,\n",
    "#             W1: W1_,\n",
    "#             W2: W2_,\n",
    "#             b1: b1_,\n",
    "#             b2: b2_\n",
    "#         }\n",
    "#         graph = topological_sort(input_node_with_value)\n",
    "        \n",
    "        training_one_batch(graph)\n",
    "        \n",
    "        learning_rate = 1e-2\n",
    "        \n",
    "        sgd_update(trainable_nodes=[W1, W2, b1, b2], learning_rate= learning_rate)\n",
    "        \n",
    "        loss += graph[-1].value\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(' Epoch : {}, loss = {:.3f}'.format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17865400898>]"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 10)"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41733926, -0.48772236, -0.59338101, -0.27259857, -0.74026221,\n",
       "        0.19427445,  0.36716642,  0.55715988, -0.8678825 , -0.98732948,\n",
       "       -0.30309415,  0.44105193, -0.49243937])"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear_output = Linear(X,W1,b1)\n",
    "# sigmoid_output = Sigmoid(linear_output)\n",
    "# yhat = Linear(sigmoid_output, W2,b2)\n",
    "# loss = MSE(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.value = X_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_of_x1 = Linear(Sigmoid(Linear(x1, W1,b1)), W2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_of_x1?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(x):\n",
    "    return 1./ (1+np.exp(-1*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.87091105])"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(_sigmoid(np.dot(X_[1],W1.value)+ b1.value), W2.value) + b2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.6"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
