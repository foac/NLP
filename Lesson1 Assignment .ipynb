{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基础理论部分\n",
    "0. Can you come up out 3 sceneraies which use AI methods?  \n",
    "Ans: 自动驾驶、远程医疗、个人助理（Javis）\n",
    "\n",
    "1. How do we use Github; Why do we use Jupyter and Pycharm;  \n",
    "Ans: \n",
    "Github还不熟悉\n",
    "Jupyter notebook有点:可以分节处理，便于展示代码运行过程；markdown格式，便于注释\n",
    "Pycharm：适用于开发，便于构建大型框架\n",
    "\n",
    "2. What's the Probability Model?\n",
    "Ans:课程中的的概念是根据语句出现的概率来判断语句合理性\n",
    "\n",
    "3. Can you came up with some sceneraies at which we could use Probability Model?  \n",
    "Ans:推荐算法\n",
    "\n",
    "4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?  \n",
    "Ans: 原因：判断根据语法自动生成的语句是否合理。难点：判断其逻辑合理性\n",
    "\n",
    "5. What's the Language Model;  \n",
    "Ans:单词序列上的概率分布\n",
    "\n",
    "6. Can you came up with some sceneraies at which we could use Language Model?  \n",
    "Ans:语音识别、语音机器人（siri等）、同声传译软件\n",
    "\n",
    "7. What's the 1-gram language model;  \n",
    "Ans:单个词出现的概率\n",
    "\n",
    "8. What's the disadvantages and advantages of 1-gram language model;  \n",
    "Ans: 实际情况中，语句合理性要联系上下文，而1-gram不能反映。\n",
    "\n",
    "9. What't the 2-gram models;  \n",
    "\n",
    "Ans: P(w1w2w3w4)≈ P(w1|w2)*P(w2|w3)*P(w3|w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_grammar=\"\"\"\n",
    "sentence => adverbial noun_phrase verb_phrase \n",
    "adverbial => null | prep noun_phrase , | prep noun_phrase dir ,\n",
    "noun_phrase => Article Adj* noun\n",
    "Adj* => null | Adj Adj*\n",
    "verb_phrase => verb noun_phrase\n",
    "prep => 在 \n",
    "dir => 上面 | 下面 | 里面 | 旁边\n",
    "verb => 看 | 打 | 玩\n",
    "Article => 一个 | 这个 | 一些 | 这些 | 那些 | null\n",
    "noun =>   篮球 | 桌子 | 小猫\n",
    "Adj => 蓝色的 | 好看的 | 小小的\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾\n",
    "报数= 我是 数字 号，\n",
    "数字 = 单个数字 | 数字 单个数字\n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 0\n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ， \n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好\n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩= null\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "service =\"\"\"\n",
    "service = 寒暄 报数 询问 业务相关 结尾\n",
    "报数= 这里是 机构 ，\n",
    "机构 = 外婆家 | 绿茶 | 新白鹿\n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 0\n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称  \n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 , | 您好 ,\n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 具体业务\n",
    "具体业务 = 订餐 | 点外卖 | 评价 | 投诉 | 人工服务 | 其他服务\n",
    "结尾 = 吗？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str,split='=>', line_split='\\n'):\n",
    "    grammar={}    \n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()]= [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(gram, target):\n",
    "    if target not in gram: # means target is a terminal expression\n",
    "        return target\n",
    "    expanded = [generate(gram, t) for t in random.choice(gram[target])]\n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expanded if e!='null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在一些好看的好看的小猫这个小小的篮球看着那些好看的'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(create_grammar(my_grammar),target= 'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好我是5号，您需要打牌吗？'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(gram=create_grammar(host,split='='), target='host')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(gram, target,n):\n",
    "    sentences=[]\n",
    "    for i in range(n):\n",
    "        s=generate(gram,target)\n",
    "        sentences.append(s)\n",
    "        #print(s)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小朋友，你好我是444号，请问你要打牌吗？\n",
      "小朋友，您好我是4号，请问你要赌博吗？\n",
      "女士，你好我是5号，请问你要喝酒吗？\n",
      "小朋友，你好我是97号，您需要赌博吗？\n",
      "女士，你好我是0号，您需要喝酒吗？\n",
      "你好我是5号，您需要打猎吗？\n",
      "先生，您好我是1号，您需要打牌吗？\n",
      "小朋友，你好我是9号，您需要打猎吗？\n",
      "您好我是6号，请问你要打猎吗？\n",
      "您好我是92号，您需要喝酒吗？\n"
     ]
    }
   ],
   "source": [
    "generate_n(gram=create_grammar(host,split='='), target='host',n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在这个篮球一些小小的蓝色的桌子打这个\n",
      "一些篮球看着那些桌子\n",
      "这些好看的好看的小小的桌子一些好看的好看的篮球\n",
      "这些小猫打这些桌子\n",
      "蓝色的小小的小猫那些蓝色的好看的蓝色的小小的\n",
      "一个好看的小猫打那些小小的\n",
      "在一些蓝色的篮球这些小猫这个桌子\n",
      "那些好看的小小的好看的蓝色的桌子那些蓝色的篮球\n",
      "在这些蓝色的小小的小猫这个打那些好看的小猫\n",
      "在一些小小的桌子好看的小猫看着一个蓝色的小猫\n"
     ]
    }
   ],
   "source": [
    "generate_n(gram=create_grammar(my_grammar), target='sentence',n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'犯我中华者虽远必诛，是有多无脑才信这句话。'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename ='movie_comments.csv'\n",
    "content = pd.read_csv(filename)\n",
    "content.head()\n",
    "#articles=content['comment'].tolist\n",
    "articles=content['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(string):\n",
    "    return re.findall('\\w+',string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_num = -1 \n",
    "articles_clean = [''.join(token(str(a))) for a in articles[:articles_num]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('articles_clean.txt','w',encoding = 'utf-8') as f:\n",
    "    for a in articles_clean:\n",
    "        f.write(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = cut(open('articles_clean.txt',encoding='utf-8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 328252),\n",
       " ('了', 102408),\n",
       " ('是', 73433),\n",
       " ('我', 50520),\n",
       " ('都', 36250),\n",
       " ('很', 34760),\n",
       " ('看', 33850),\n",
       " ('电影', 33638),\n",
       " ('也', 32064),\n",
       " ('和', 31291)]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    return words_count[word] / len(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_2_GRAM = [ ''.join(TOKENS[i:i+2]) for i in range(len(TOKENS[:-2]))]\n",
    "words_count_2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的电影', 8631),\n",
       " ('看的', 7075),\n",
       " ('都是', 6335),\n",
       " ('让人', 5278),\n",
       " ('的故事', 4707),\n",
       " ('看了', 4538),\n",
       " ('也是', 4407),\n",
       " ('的时候', 4398),\n",
       " ('的是', 4348),\n",
       " ('的人', 4344),\n",
       " ('看完', 3741),\n",
       " ('我的', 3487),\n",
       " ('的片子', 3350),\n",
       " ('让我', 3271),\n",
       " ('这样的', 2852),\n",
       " ('这部电影', 2722),\n",
       " ('很好', 2624),\n",
       " ('电影的', 2551),\n",
       " ('不知道', 2539),\n",
       " ('的感觉', 2501)]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_2.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if word1 + word2 in words_count_2:\n",
    "        return words_count_2[word1 + word2]/len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1/len(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability(sentence):\n",
    "    words = cut(sentence)\n",
    "    sentence_pro = 1\n",
    "    for i,word in enumerate(sentence[:-1]):\n",
    "        next_ = sentence[i+1]\n",
    "        probability = prob_2(word, next_)\n",
    "        sentence_pro *= probability\n",
    "    return sentence_pro        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(gram, target,n):\n",
    "   # sentences=generate_n(gram, target,n)\n",
    "    sentences_prob=[]\n",
    "    for i in range(n):\n",
    "        s=generate(gram,target)\n",
    "        f = get_probability(s)\n",
    "        sentences_prob.append((s,f))\n",
    "        #print(s)\n",
    "    sentences_prob=sorted(sentences_prob, key = lambda x: x[1], reverse=True)\n",
    "    return sentences_prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('小朋友你好,这里是绿茶，您需要评价吗？', 2.538868558360583e-118),\n",
       " ('您好,这里是外婆家，您需要其他服务吗？', 8.462895194535276e-119),\n",
       " ('你好,这里是外婆家，请问你要其他服务吗？', 1.3609988935581604e-121),\n",
       " ('女士您好,这里是外婆家，请问你要投诉吗？', 1.3609988935581604e-121),\n",
       " ('小朋友您好,这里是新白鹿，请问你要评价吗？', 1.7592519891583494e-126),\n",
       " ('先生您好,这里是绿茶，请问你要其他服务吗？', 9.099579254267326e-128),\n",
       " ('小朋友您好,这里是外婆家，请问你要评价吗？', 3.0331930847557746e-128),\n",
       " ('女士您好,这里是新白鹿，您需要人工服务吗？', 2.1941890108682294e-129),\n",
       " ('先生你好,这里是外婆家，您需要人工服务吗？', 3.7830845014969484e-131),\n",
       " ('小朋友您好,这里是外婆家，您需要点外卖吗？', 4.2034272238854964e-132)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq= generate_best(gram=create_grammar(service,split='='), target='service',n=10)\n",
    "seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('蓝色的篮球玩小猫', 1.856970087350936e-45),\n",
       " ('在这个篮球,这些桌子看那些桌子', 7.538018933160809e-90),\n",
       " ('一些好看的小猫玩这个好看的蓝色的篮球', 3.8283171953160955e-97),\n",
       " ('在小猫下面,一些桌子玩这些好看的蓝色的篮球', 6.473458398017733e-125),\n",
       " ('在篮球里面,一些好看的蓝色的好看的小猫打一些小猫', 1.6898893266570786e-136),\n",
       " ('在一个篮球,这个小小的小小的桌子打这些小小的桌子', 1.4147960687930806e-140),\n",
       " ('在蓝色的蓝色的好看的小小的小小的小猫,这些篮球打那些篮球', 1.0394970890527222e-155),\n",
       " ('在这个小小的好看的篮球,一个蓝色的桌子打一些蓝色的小小的蓝色的桌子', 9.694788432653985e-190),\n",
       " ('在这个蓝色的小小的好看的小小的篮球,这个篮球打这些好看的蓝色的好看的桌子', 3.20110030310247e-198),\n",
       " ('在一个蓝色的好看的好看的蓝色的好看的好看的小小的好看的桌子旁边,一个好看的小猫看这些蓝色的小小的小小的好看的篮球',\n",
       "  3.9248323876740625e-291)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2= generate_best(gram=create_grammar(my_grammar), target='sentence',n=10)\n",
    "seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
